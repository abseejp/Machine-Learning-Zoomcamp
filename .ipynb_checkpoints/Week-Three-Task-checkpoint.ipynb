{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcd9b18d",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68a87fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e69985e",
   "metadata": {},
   "source": [
    "#### Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8352ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c80db5",
   "metadata": {},
   "source": [
    "#### Data preparation\n",
    "- Select only the features from above and fill in the missing values with 0.\n",
    "- Create a new column rooms_per_household by dividing the column total_rooms by the column households from dataframe.\n",
    "- Create a new column bedrooms_per_room by dividing the column total_bedrooms by the column total_rooms from dataframe.\n",
    "- Create a new column population_per_household by dividing the column population by the column households from dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "399306f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['latitude', 'longitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income', 'median_house_value',\n",
    "'ocean_proximity']\n",
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10833ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "latitude                0\n",
       "longitude               0\n",
       "housing_median_age      0\n",
       "total_rooms             0\n",
       "total_bedrooms        207\n",
       "population              0\n",
       "households              0\n",
       "median_income           0\n",
       "median_house_value      0\n",
       "ocean_proximity         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "941e41ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56b04248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "latitude              0\n",
       "longitude             0\n",
       "housing_median_age    0\n",
       "total_rooms           0\n",
       "total_bedrooms        0\n",
       "population            0\n",
       "households            0\n",
       "median_income         0\n",
       "median_house_value    0\n",
       "ocean_proximity       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3e3ce51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rooms_per_household'] = df['total_rooms']/ df['households']\n",
    "df['bedrooms_per_room '] = df['total_bedrooms']/ df['total_rooms']\n",
    "df['population_per_household  '] = df['population']/ df['households']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a4a514",
   "metadata": {},
   "source": [
    "#### Question 1\n",
    "- What is the most frequent observation (mode) for the column ocean_proximity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "892eb900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<1H OCEAN'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ocean_proximity'].mode()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833692b9",
   "metadata": {},
   "source": [
    "#### Question 2\n",
    "- Create the correlation matrix for the numerical features of your train dataset.\n",
    "- In a correlation matrix, you compute the correlation coefficient between every pair of features in the dataset.\n",
    "- What are the two features that have the biggest correlation in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81e6e013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>rooms_per_household</th>\n",
       "      <th>bedrooms_per_room</th>\n",
       "      <th>population_per_household</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.924664</td>\n",
       "      <td>0.011173</td>\n",
       "      <td>-0.036100</td>\n",
       "      <td>-0.065318</td>\n",
       "      <td>-0.108785</td>\n",
       "      <td>-0.071035</td>\n",
       "      <td>-0.079809</td>\n",
       "      <td>-0.144160</td>\n",
       "      <td>0.106389</td>\n",
       "      <td>-0.104112</td>\n",
       "      <td>0.002366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>-0.924664</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.108197</td>\n",
       "      <td>0.044568</td>\n",
       "      <td>0.068082</td>\n",
       "      <td>0.099773</td>\n",
       "      <td>0.055310</td>\n",
       "      <td>-0.015176</td>\n",
       "      <td>-0.045967</td>\n",
       "      <td>-0.027540</td>\n",
       "      <td>0.084836</td>\n",
       "      <td>0.002476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housing_median_age</th>\n",
       "      <td>0.011173</td>\n",
       "      <td>-0.108197</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.361262</td>\n",
       "      <td>-0.317063</td>\n",
       "      <td>-0.296244</td>\n",
       "      <td>-0.302916</td>\n",
       "      <td>-0.119034</td>\n",
       "      <td>0.105623</td>\n",
       "      <td>-0.153277</td>\n",
       "      <td>0.125396</td>\n",
       "      <td>0.013191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rooms</th>\n",
       "      <td>-0.036100</td>\n",
       "      <td>0.044568</td>\n",
       "      <td>-0.361262</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920196</td>\n",
       "      <td>0.857126</td>\n",
       "      <td>0.918484</td>\n",
       "      <td>0.198050</td>\n",
       "      <td>0.134153</td>\n",
       "      <td>0.133798</td>\n",
       "      <td>-0.174583</td>\n",
       "      <td>-0.024581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_bedrooms</th>\n",
       "      <td>-0.065318</td>\n",
       "      <td>0.068082</td>\n",
       "      <td>-0.317063</td>\n",
       "      <td>0.920196</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866266</td>\n",
       "      <td>0.966507</td>\n",
       "      <td>-0.007295</td>\n",
       "      <td>0.049148</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>0.122205</td>\n",
       "      <td>-0.028019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>-0.108785</td>\n",
       "      <td>0.099773</td>\n",
       "      <td>-0.296244</td>\n",
       "      <td>0.857126</td>\n",
       "      <td>0.866266</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.907222</td>\n",
       "      <td>0.004834</td>\n",
       "      <td>-0.024650</td>\n",
       "      <td>-0.072213</td>\n",
       "      <td>0.031397</td>\n",
       "      <td>0.069863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>households</th>\n",
       "      <td>-0.071035</td>\n",
       "      <td>0.055310</td>\n",
       "      <td>-0.302916</td>\n",
       "      <td>0.918484</td>\n",
       "      <td>0.966507</td>\n",
       "      <td>0.907222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013033</td>\n",
       "      <td>0.065843</td>\n",
       "      <td>-0.080598</td>\n",
       "      <td>0.059818</td>\n",
       "      <td>-0.027309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_income</th>\n",
       "      <td>-0.079809</td>\n",
       "      <td>-0.015176</td>\n",
       "      <td>-0.119034</td>\n",
       "      <td>0.198050</td>\n",
       "      <td>-0.007295</td>\n",
       "      <td>0.004834</td>\n",
       "      <td>0.013033</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.688075</td>\n",
       "      <td>0.326895</td>\n",
       "      <td>-0.573836</td>\n",
       "      <td>0.018766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_house_value</th>\n",
       "      <td>-0.144160</td>\n",
       "      <td>-0.045967</td>\n",
       "      <td>0.105623</td>\n",
       "      <td>0.134153</td>\n",
       "      <td>0.049148</td>\n",
       "      <td>-0.024650</td>\n",
       "      <td>0.065843</td>\n",
       "      <td>0.688075</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.151948</td>\n",
       "      <td>-0.238759</td>\n",
       "      <td>-0.023737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rooms_per_household</th>\n",
       "      <td>0.106389</td>\n",
       "      <td>-0.027540</td>\n",
       "      <td>-0.153277</td>\n",
       "      <td>0.133798</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>-0.072213</td>\n",
       "      <td>-0.080598</td>\n",
       "      <td>0.326895</td>\n",
       "      <td>0.151948</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.387465</td>\n",
       "      <td>-0.004852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms_per_room</th>\n",
       "      <td>-0.104112</td>\n",
       "      <td>0.084836</td>\n",
       "      <td>0.125396</td>\n",
       "      <td>-0.174583</td>\n",
       "      <td>0.122205</td>\n",
       "      <td>0.031397</td>\n",
       "      <td>0.059818</td>\n",
       "      <td>-0.573836</td>\n",
       "      <td>-0.238759</td>\n",
       "      <td>-0.387465</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population_per_household</th>\n",
       "      <td>0.002366</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.013191</td>\n",
       "      <td>-0.024581</td>\n",
       "      <td>-0.028019</td>\n",
       "      <td>0.069863</td>\n",
       "      <td>-0.027309</td>\n",
       "      <td>0.018766</td>\n",
       "      <td>-0.023737</td>\n",
       "      <td>-0.004852</td>\n",
       "      <td>0.003047</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            latitude  longitude  housing_median_age  \\\n",
       "latitude                    1.000000  -0.924664            0.011173   \n",
       "longitude                  -0.924664   1.000000           -0.108197   \n",
       "housing_median_age          0.011173  -0.108197            1.000000   \n",
       "total_rooms                -0.036100   0.044568           -0.361262   \n",
       "total_bedrooms             -0.065318   0.068082           -0.317063   \n",
       "population                 -0.108785   0.099773           -0.296244   \n",
       "households                 -0.071035   0.055310           -0.302916   \n",
       "median_income              -0.079809  -0.015176           -0.119034   \n",
       "median_house_value         -0.144160  -0.045967            0.105623   \n",
       "rooms_per_household         0.106389  -0.027540           -0.153277   \n",
       "bedrooms_per_room          -0.104112   0.084836            0.125396   \n",
       "population_per_household    0.002366   0.002476            0.013191   \n",
       "\n",
       "                            total_rooms  total_bedrooms  population  \\\n",
       "latitude                      -0.036100       -0.065318   -0.108785   \n",
       "longitude                      0.044568        0.068082    0.099773   \n",
       "housing_median_age            -0.361262       -0.317063   -0.296244   \n",
       "total_rooms                    1.000000        0.920196    0.857126   \n",
       "total_bedrooms                 0.920196        1.000000    0.866266   \n",
       "population                     0.857126        0.866266    1.000000   \n",
       "households                     0.918484        0.966507    0.907222   \n",
       "median_income                  0.198050       -0.007295    0.004834   \n",
       "median_house_value             0.134153        0.049148   -0.024650   \n",
       "rooms_per_household            0.133798        0.002717   -0.072213   \n",
       "bedrooms_per_room             -0.174583        0.122205    0.031397   \n",
       "population_per_household      -0.024581       -0.028019    0.069863   \n",
       "\n",
       "                            households  median_income  median_house_value  \\\n",
       "latitude                     -0.071035      -0.079809           -0.144160   \n",
       "longitude                     0.055310      -0.015176           -0.045967   \n",
       "housing_median_age           -0.302916      -0.119034            0.105623   \n",
       "total_rooms                   0.918484       0.198050            0.134153   \n",
       "total_bedrooms                0.966507      -0.007295            0.049148   \n",
       "population                    0.907222       0.004834           -0.024650   \n",
       "households                    1.000000       0.013033            0.065843   \n",
       "median_income                 0.013033       1.000000            0.688075   \n",
       "median_house_value            0.065843       0.688075            1.000000   \n",
       "rooms_per_household          -0.080598       0.326895            0.151948   \n",
       "bedrooms_per_room             0.059818      -0.573836           -0.238759   \n",
       "population_per_household     -0.027309       0.018766           -0.023737   \n",
       "\n",
       "                            rooms_per_household  bedrooms_per_room   \\\n",
       "latitude                               0.106389           -0.104112   \n",
       "longitude                             -0.027540            0.084836   \n",
       "housing_median_age                    -0.153277            0.125396   \n",
       "total_rooms                            0.133798           -0.174583   \n",
       "total_bedrooms                         0.002717            0.122205   \n",
       "population                            -0.072213            0.031397   \n",
       "households                            -0.080598            0.059818   \n",
       "median_income                          0.326895           -0.573836   \n",
       "median_house_value                     0.151948           -0.238759   \n",
       "rooms_per_household                    1.000000           -0.387465   \n",
       "bedrooms_per_room                     -0.387465            1.000000   \n",
       "population_per_household              -0.004852            0.003047   \n",
       "\n",
       "                            population_per_household    \n",
       "latitude                                      0.002366  \n",
       "longitude                                     0.002476  \n",
       "housing_median_age                            0.013191  \n",
       "total_rooms                                  -0.024581  \n",
       "total_bedrooms                               -0.028019  \n",
       "population                                    0.069863  \n",
       "households                                   -0.027309  \n",
       "median_income                                 0.018766  \n",
       "median_house_value                           -0.023737  \n",
       "rooms_per_household                          -0.004852  \n",
       "bedrooms_per_room                             0.003047  \n",
       "population_per_household                      1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e24ffb8",
   "metadata": {},
   "source": [
    "- Make median_house_value binary\n",
    "- We need to turn the median_house_value variable from numeric into binary.\n",
    "- Let's create a variable above_average which is 1 if the median_house_value is above its mean value and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7aab7beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['above_average'] = df['median_house_value'].apply(lambda x: 1 if x > df['median_house_value'].mean() else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b00620",
   "metadata": {},
   "source": [
    "- Split the data\n",
    "- Split your data in train/val/test sets, with 60%/20%/20% distribution.\n",
    "- Use Scikit-Learn for that (the train_test_split function) and set the seed to 42.\n",
    "- Make sure that the target value (median_house_value) is not in your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdfa61e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train_full, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "X_train, X_val = train_test_split(df_train_full, test_size=0.25, random_state=42)\n",
    "\n",
    "y_train = X_train.above_average.values\n",
    "y_val = X_val.above_average.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad46b12",
   "metadata": {},
   "source": [
    "#### Question 3\n",
    "- Calculate the mutual information score with the (binarized) price for the categorical variable that we have. Use the training set only.\n",
    "- What is the value of mutual information?\n",
    "- Round it to 2 decimal digits using round(score, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9daa29a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mutual_info_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e04ebd43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(mutual_info_score(X_train['ocean_proximity'], X_train['above_average']), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3064b695",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(['above_average', 'median_house_value'], axis = 1, inplace = True)\n",
    "X_val.drop(['above_average', 'median_house_value'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f4e042",
   "metadata": {},
   "source": [
    "#### Question 4\n",
    "- Now let's train a logistic regression\n",
    "- Remember that we have one categorical variable ocean_proximity in the data. Include it using one-hot encoding.\n",
    "- Fit the model on the training dataset.\n",
    "- To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:\n",
    "- model = LogisticRegression(solver=\"liblinear\", C=1.0, max_iter=1000, random_state=42)\n",
    "- Calculate the accuracy on the validation dataset and round it to 2 decimal digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7ddbfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3864a4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = X_train.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b10faa82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DictVectorizer(sparse=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv = DictVectorizer(sparse=False)\n",
    "dv.fit(train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "711e8a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = dv.transform(train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2683cc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02253b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=42, solver='liblinear')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model = LogisticRegression(solver=\"liblinear\", C=1.0, max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4fe8c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.13173447]),\n",
       " array([[ 3.41281905e-01,  3.98762376e-03,  3.60259800e-02,\n",
       "          1.30140624e-01,  9.15912335e-02,  1.21623656e+00,\n",
       "          4.74922642e-01, -1.76232572e+00,  3.54534386e-02,\n",
       "          2.29334213e-01,  8.90880953e-01, -1.63818534e-03,\n",
       "          1.04225229e-02, -9.88403287e-03,  1.83522544e-03,\n",
       "         -1.42062788e-04]]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_, model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab5d8054",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dict = X_val.to_dict(orient='records')\n",
    "X_val = dv.transform(val_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55bf20c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_proba(X_val)[:, 1]\n",
    "predictions = [1 if i > 0.5 else 0 for i in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4cf90c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "overall_average = round(accuracy_score(y_val, predictions),2)\n",
    "overall_average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d4c254",
   "metadata": {},
   "source": [
    "#### Question 5\n",
    "- Let's find the least useful feature using the feature elimination technique.\n",
    "- Train a model with all these features (using the same parameters as in Q4).\n",
    "- Now exclude each feature from this set and train a model without it. Record the accuracy for each model.\n",
    "- For each feature, calculate the difference between the original accuracy and the accuracy without the feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7ff995d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['total_rooms', 'total_bedrooms', 'population', 'households']\n",
    "def model_build(data):\n",
    "    for feature in features:\n",
    "        data_1 = data.drop(feature, axis = 1)\n",
    "\n",
    "        df_train_full, df_test = train_test_split(data_1, test_size=0.2, random_state=42)\n",
    "        \n",
    "        X_train, X_val = train_test_split(df_train_full, test_size=0.25, random_state=42)\n",
    "\n",
    "        y_train = X_train.above_average.values\n",
    "        y_val = X_val.above_average.values\n",
    "        \n",
    "        X_train.drop(['above_average', 'median_house_value'], axis = 1, inplace = True)\n",
    "        X_val.drop(['above_average', 'median_house_value'], axis = 1, inplace = True)\n",
    "\n",
    "        \n",
    "        \n",
    "        train_dict = X_train.to_dict(orient='records')\n",
    "        dv = DictVectorizer(sparse=False)\n",
    "        dv.fit(train_dict)\n",
    "        X_train = dv.transform(train_dict)\n",
    "        \n",
    "        model = LogisticRegression(solver=\"liblinear\", C=1.0, max_iter=1000, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        val_dict = X_val.to_dict(orient='records')\n",
    "        X_val = dv.transform(val_dict)\n",
    "        \n",
    "        predictions = model.predict_proba(X_val)[:, 1]\n",
    "        predictions = [1 if i > 0.5 else 0 for i in predictions]\n",
    "        \n",
    "        accuracy = round(accuracy_score(y_val, predictions),4)\n",
    "        \n",
    "        \n",
    "        \n",
    "        print('Accuracy after removing ', feature, 'is ', accuracy, 'and model difference is', np.round(abs(overall_average- accuracy),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3fe5bb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after removing  total_rooms is  0.8362 and model difference is 0.0038\n",
      "Accuracy after removing  total_bedrooms is  0.8367 and model difference is 0.0033\n",
      "Accuracy after removing  population is  0.8263 and model difference is 0.0137\n",
      "Accuracy after removing  households is  0.8338 and model difference is 0.0062\n"
     ]
    }
   ],
   "source": [
    "model_build(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c6d7fc",
   "metadata": {},
   "source": [
    "#### Question 6\n",
    "- For this question, we'll see how to use a linear regression model from Scikit-Learn\n",
    "- We'll need to use the original column 'median_house_value'. Apply the logarithmic transformation to this column.\n",
    "- Fit the Ridge regression model (model = Ridge(alpha=a, solver=\"sag\", random_state=42)) on the training data.\n",
    "- This model has a parameter alpha. Let's try the following values: [0, 0.01, 0.1, 1, 10]\n",
    "- Which of these alphas leads to the best RMSE on the validation set? Round your RMSE scores to 3 decimal digits.\n",
    "- If there are multiple options, select the smallest alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d598232e",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_values = [0, 0.01, 0.1, 1, 10]\n",
    "def linear_model_build(data):\n",
    "    for value in alpha_values:\n",
    "\n",
    "        df_train_full, df_test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "        \n",
    "        X_train, X_val = train_test_split(df_train_full, test_size=0.25, random_state=42)\n",
    "\n",
    "        y_train = np.log(X_train.median_house_value).values\n",
    "        y_val = np.log(X_val.median_house_value).values\n",
    "        \n",
    "        X_train.drop(['above_average', 'median_house_value'], axis = 1, inplace = True)\n",
    "        X_val.drop(['above_average', 'median_house_value'], axis = 1, inplace = True)\n",
    "\n",
    "        \n",
    "        \n",
    "        train_dict = X_train.to_dict(orient='records')\n",
    "        dv = DictVectorizer(sparse=False)\n",
    "        dv.fit(train_dict)\n",
    "        X_train = dv.transform(train_dict)\n",
    "        \n",
    "        from sklearn.linear_model import Ridge\n",
    "        model = Ridge(alpha=value, solver=\"sag\", random_state=42)\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        val_dict = X_val.to_dict(orient='records')\n",
    "        X_val = dv.transform(val_dict)\n",
    "        \n",
    "        predictions = model.predict(X_val)\n",
    "        \n",
    "        from sklearn.metrics import mean_squared_error\n",
    "        MSE = mean_squared_error(y_val, predictions)\n",
    "        \n",
    "        import math\n",
    "        RMSE = math.sqrt(MSE)\n",
    "        \n",
    "        print('The RMSE for alpha value of', value, 'is', np.round(RMSE,3))\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "806895e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE for alpha value of 0 is 0.524\n",
      "The RMSE for alpha value of 0.01 is 0.524\n",
      "The RMSE for alpha value of 0.1 is 0.524\n",
      "The RMSE for alpha value of 1 is 0.524\n",
      "The RMSE for alpha value of 10 is 0.524\n"
     ]
    }
   ],
   "source": [
    "linear_model_build(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fae248",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
